{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25905937",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "702d2e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012486162921209907, 0.9497182859911791)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def nhl_correlation():\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    cities['NHL'] = cities['NHL'].str.replace(\"\\[.*\\]\", \"\", regex=True)\n",
    "\n",
    "    Big4='NHL'\n",
    "    \n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = (pd.melt(team, id_vars=['Metropolitan area'])\n",
    "            .drop(columns=['variable'])\n",
    "            .replace(\"\",np.nan)\n",
    "            .replace(\"—\",np.nan)\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .rename(columns = {\"value\":\"team\"}))\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team['team'] = team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "    team = team.rename(columns = {'Population (2016 est.)[8]': 'Population'})\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    \n",
    "    df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'\\*',\"\", regex=True)\n",
    "    df = df[['team','W','L']]\n",
    "\n",
    "    dropList=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        row=df.iloc[i]\n",
    "        if row['team']==row['W'] and row['L']==row['W']:\n",
    "            dropList.append(i)\n",
    "    df=df.drop(dropList)\n",
    "\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    df = df.astype({'team': str,'W': int, 'L': int})\n",
    "    df['W/L%'] = df['W']/(df['W']+df['L'])\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "    \n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "nhl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d66710b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.17636350642182938, 0.36932106185547353)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "\n",
    "def nba_correlation():\n",
    "    cities['NBA'] = cities['NBA'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "    Big4='NBA'\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"}, inplace=True)\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team = pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team'] = team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "\n",
    "    df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\", regex=True)\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\", regex=True)\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\", regex=True)\n",
    "    df = df[['team','W/L%']]\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "\n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31f7565f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15003737475409498, 0.46442827201123427)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "\n",
    "def mlb_correlation():\n",
    "    cities['MLB'] = cities['MLB'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "    Big4='MLB'\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"}, inplace=True)\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('\\ Sox','Sox', regex=True)\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "\n",
    "    df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\", regex=True)\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\", regex=True)\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\", regex=True)\n",
    "    df = df[['team','W-L%']]\n",
    "    df.rename(columns={\"W-L%\": \"W/L%\"},inplace=True)\n",
    "    df['team']= df['team'].str.replace('\\ Sox','Sox', regex=True)\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from _df in the same order as cities[\"Metropolitan area\"]   \n",
    "    \n",
    "    print(len(win_loss_by_region))\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "    \n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1ee3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.004282141436393017, 0.9824114740736553)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def nfl_correlation(): \n",
    "    # YOUR CODE HERE\n",
    "    cities['NFL'] = cities['NFL'].str.replace(r\"\\[.*\\]\", \"\", regex = True)\n",
    "    Big4='NFL'\n",
    "    cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"}, inplace=True)\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex = True)\n",
    "    \n",
    "    df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    df = df[df['year'] == 2018]\n",
    "    df['team'] = df['team'].str.replace(r'[\\*]',\"\", regex = True)\n",
    "    df['team'] = df['team'].str.replace(r'\\(\\d*\\)',\"\", regex = True)\n",
    "    df['team'] = df['team'].str.replace(r'[\\xa0]',\"\", regex = True)\n",
    "    df = df[['team','W-L%']]\n",
    "    df.rename(columns={\"W-L%\": \"W/L%\"},inplace=True)\n",
    "    dropList=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        row=df.iloc[i]\n",
    "        if row['team']==row['W/L%']:\n",
    "            dropList.append(i)\n",
    "    df= df.drop(dropList)\n",
    "\n",
    "    df['team'] = df['team'].str.replace('[\\w.]* ','', regex = True)\n",
    "    df['team'] = df['team'].str.replace('+','', regex = True)\n",
    "    df = df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team, df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    \n",
    "    population_by_region = merge['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merge['W/L%'] # pass in win/loss ratio from nfl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    print(len(win_loss_by_region))\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a899a577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NHL</th>\n",
       "      <th>MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NFL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937509</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.803459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>0.937509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>0.949566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHL</th>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLB</th>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.949566</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NFL       NBA       NHL       MLB\n",
       "NFL       NaN  0.937509  0.030318  0.803459\n",
       "NBA  0.937509       NaN  0.022386  0.949566\n",
       "NHL  0.030318  0.022386       NaN  0.000703\n",
       "MLB  0.803459  0.949566  0.000703       NaN"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "cities = pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
    "cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"}, inplace=True)\n",
    "cities['NFL'] = cities['NFL'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "cities['MLB'] = cities['MLB'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "cities['NBA'] = cities['NBA'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "cities['NHL'] = cities['NHL'].str.replace(r\"\\[.*\\]\", \"\", regex=True)\n",
    "\n",
    "\n",
    "def nhl_df():\n",
    "    Big4='NHL'\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "    \n",
    "    _df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    _df = _df[_df['year'] == 2018]\n",
    "    _df['team'] = _df['team'].str.replace(r'\\*',\"\", regex=True)\n",
    "    _df = _df[['team','W','L']]\n",
    "\n",
    "    dropList=[]\n",
    "    for i in range(_df.shape[0]):\n",
    "        row=_df.iloc[i]\n",
    "        if row['team']==row['W'] and row['L']==row['W']:\n",
    "            dropList.append(i)\n",
    "    _df=_df.drop(dropList)\n",
    "\n",
    "    _df['team'] = _df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    _df = _df.astype({'team': str,'W': int, 'L': int})\n",
    "    _df['W/L%'] = _df['W']/(_df['W']+_df['L'])\n",
    "    \n",
    "    merge=pd.merge(team,_df,'inner', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})  \n",
    "\n",
    "    return merge[['W/L%']]\n",
    "\n",
    "\n",
    "\n",
    "def nba_df():\n",
    "    Big4='NBA'\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "\n",
    "    _df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    _df = _df[_df['year'] == 2018]\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\*]',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'\\(\\d*\\)',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\xa0]',\"\", regex=True)\n",
    "    _df = _df[['team','W/L%']]\n",
    "    _df['team'] = _df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    _df = _df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,_df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "    return merge[['W/L%']]\n",
    "\n",
    "\n",
    "\n",
    "def mlb_df(): \n",
    "    Big4='MLB'\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('\\ Sox','Sox', regex=True)\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "\n",
    "    _df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    _df = _df[_df['year'] == 2018]\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\*]',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'\\(\\d*\\)',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\xa0]',\"\", regex=True)\n",
    "    _df = _df[['team','W-L%']]\n",
    "    _df.rename(columns={\"W-L%\": \"W/L%\"},inplace=True)\n",
    "    _df['team']=_df['team'].str.replace('\\ Sox','Sox', regex=True)\n",
    "    _df['team'] = _df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    _df = _df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,_df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "\n",
    "    return merge[['W/L%']]\n",
    "\n",
    "def nfl_df(): \n",
    "    Big4='NFL'\n",
    "    team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
    "    team['Metropolitan area']=cities['Metropolitan area']\n",
    "    team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\",np.nan).replace(\"—\",np.nan).dropna().reset_index().rename(columns = {\"value\":\"team\"})\n",
    "    team=pd.merge(team,cities,how='left',on = 'Metropolitan area').iloc[:,1:4]\n",
    "    team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
    "    team['team']=team['team'].str.replace('[\\w.]*\\ ','', regex=True)\n",
    "    \n",
    "    _df=pd.read_csv(\"assets/\"+str.lower(Big4)+\".csv\")\n",
    "    _df = _df[_df['year'] == 2018]\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\*]',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'\\(\\d*\\)',\"\", regex=True)\n",
    "    _df['team'] = _df['team'].str.replace(r'[\\xa0]',\"\", regex=True)\n",
    "    _df = _df[['team','W-L%']]\n",
    "    _df.rename(columns={\"W-L%\": \"W/L%\"},inplace=True)\n",
    "    dropList=[]\n",
    "    for i in range(_df.shape[0]):\n",
    "        row=_df.iloc[i]\n",
    "        if row['team']==row['W/L%']:\n",
    "            dropList.append(i)\n",
    "    _df=_df.drop(dropList)\n",
    "\n",
    "    _df['team'] = _df['team'].str.replace('[\\w.]* ','', regex=True)\n",
    "    _df['team'] = _df['team'].str.replace('+','', regex=True)\n",
    "    _df = _df.astype({'team': str,'W/L%': float})\n",
    "    \n",
    "    merge=pd.merge(team,_df,'outer', on = 'team')\n",
    "    merge=merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
    "\n",
    "    return merge[['W/L%']]\n",
    "\n",
    "def create_df(sport):\n",
    "    if sport =='NFL':\n",
    "        return nfl_df()\n",
    "    elif sport =='NBA':\n",
    "        return nba_df()\n",
    "    elif sport =='NHL':\n",
    "        return nhl_df()\n",
    "    elif sport =='MLB':\n",
    "        return mlb_df()\n",
    "    else:\n",
    "        print(\"ERROR with intput!\")\n",
    "\n",
    "\n",
    "def sports_team_performance():\n",
    "    # Note: p_values is a full dataframe, so df.loc[\"NFL\",\"NBA\"] should be the same as df.loc[\"NBA\",\"NFL\"] and\n",
    "    # df.loc[\"NFL\",\"NFL\"] should return np.nan\n",
    "    sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "    p_values = pd.DataFrame({k:np.nan for k in sports}, index=sports)\n",
    "    \n",
    "    for i in sports:\n",
    "        for j in sports:\n",
    "            if i !=j :\n",
    "                merge=pd.merge(create_df(i),create_df(j),'inner', on = ['Metropolitan area'])\n",
    "                p_values.loc[i, j]=stats.ttest_rel(merge['W/L%_x'],merge['W/L%_y'])[1]\n",
    "\n",
    "    \n",
    "    assert abs(p_values.loc[\"NBA\", \"NHL\"] - 0.02) <= 1e-2, \"The NBA-NHL p-value should be around 0.02\"\n",
    "    assert abs(p_values.loc[\"MLB\", \"NFL\"] - 0.80) <= 1e-2, \"The MLB-NFL p-value should be around 0.80\"\n",
    "    return p_values\n",
    "sports_team_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88657a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
